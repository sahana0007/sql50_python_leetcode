{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "1757"
      ],
      "metadata": {
        "id": "4_M3Rby_e2ZP"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yp7O1c8ud4Ym",
        "outputId": "1b4784a3-ea7e-4d2c-fb0a-71b169cc4f52"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   product_id\n",
            "0           1\n",
            "3           4\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "def recyclable_and_low_fat_products(products: pd.DataFrame) -> pd.DataFrame:\n",
        "    # Step 2: Filter the DataFrame for products that are both low fat and recyclable\n",
        "    filtered_df = products[(products['low_fats'] == 'Y') & (products['recyclable'] == 'Y')]\n",
        "\n",
        "    # Step 3: Extract the product_ids for the filtered products\n",
        "    result = filtered_df[['product_id']]\n",
        "\n",
        "    return result\n",
        "\n",
        "# Example usage:\n",
        "data = {\n",
        "    'product_id': [1, 2, 3, 4, 5],\n",
        "    'low_fats': ['Y', 'Y', 'N', 'Y', 'N'],\n",
        "    'recyclable': ['Y', 'N', 'Y', 'Y', 'N']\n",
        "}\n",
        "\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "result_df = recyclable_and_low_fat_products(df)\n",
        "print(result_df)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.functions import col\n",
        "\n",
        "# Define the schema for the DataFrame\n",
        "schema = [\"product_id\", \"low_fats\", \"recyclable\"]\n",
        "\n",
        "# Create a DataFrame from the sample data and schema\n",
        "products_df = spark.createDataFrame(data, schema)\n",
        "\n",
        "# Filter the DataFrame to include only products that are both low fat and recyclable\n",
        "filtered_df = products_df.filter((col(\"low_fats\") == \"Y\") & (col(\"recyclable\") == \"Y\"))\n",
        "\n",
        "# Select only the product_id column\n",
        "result_df = filtered_df.select(\"product_id\")\n",
        "\n",
        "# Show the result\n",
        "result_df.show()\n"
      ],
      "metadata": {
        "id": "XWFsxKAiebq1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "595"
      ],
      "metadata": {
        "id": "nEAprhrBei3H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "def big_countries(world: pd.DataFrame) -> pd.DataFrame:\n",
        "    # Filter countries based on area and population conditions\n",
        "    df_w = world[(world['area'] >= 3000000) | (world['population'] >= 25000000)]\n",
        "\n",
        "    # Select only 'name', 'population', and 'area' columns\n",
        "    results = df_w[['name', 'population', 'area']]\n",
        "\n",
        "    return results\n",
        "\n",
        "# Sample test data for the world DataFrame\n",
        "data = {\n",
        "    'name': ['United States', 'Canada', 'India', 'Australia', 'Brazil'],\n",
        "    'population': [331002651, 38005238, 1380004385, 25499884, 212559417],\n",
        "    'area': [9833520, 9984670, 3287263, 7692024, 8515767]\n",
        "}\n",
        "\n",
        "world_df = pd.DataFrame(data)\n",
        "\n",
        "# Call the big_countries function with the sample test data\n",
        "big_countries_result = big_countries(world_df)\n",
        "\n",
        "# Print the filtered DataFrame containing information about big countries\n",
        "print(big_countries_result)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6ujAG6zkec8i",
        "outputId": "dfc9160f-86b1-4a87-814d-f97784835a83"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "            name  population     area\n",
            "0  United States   331002651  9833520\n",
            "1         Canada    38005238  9984670\n",
            "2          India  1380004385  3287263\n",
            "3      Australia    25499884  7692024\n",
            "4         Brazil   212559417  8515767\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "1148"
      ],
      "metadata": {
        "id": "TFBUMyIkfHdE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "def article_views_i(views: pd.DataFrame) -> pd.DataFrame:\n",
        "    result = views[views['viewer_id'] == views['author_id']]['author_id'].drop_duplicates().sort_values()\n",
        "    result = result.rename('id').reset_index(drop=True)\n",
        "    result_df = pd.DataFrame(result)  # Convert Series to DataFrame\n",
        "    return result_df\n",
        "\n",
        "# Sample test data for the views DataFrame\n",
        "data = {\n",
        "    'viewer_id': [100, 200, 200, 300, 300, 400, 500],\n",
        "    'author_id': [100, 100, 200, 300, 300, 500, 600]\n",
        "}\n",
        "\n",
        "views_df = pd.DataFrame(data)\n",
        "\n",
        "# Call the article_views_i function with the sample test data\n",
        "result_df = article_views_i(views_df)\n",
        "\n",
        "# Print the resulting DataFrame containing the distinct author_ids who viewed their own articles\n",
        "print(result_df)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uHTa_nILe05P",
        "outputId": "9b955f52-dfa4-499b-92a1-d6100524b28b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    id\n",
            "0  100\n",
            "1  200\n",
            "2  300\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "1683"
      ],
      "metadata": {
        "id": "e5CyBvWoelyE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "def invalid_tweets(tweets: pd.DataFrame) -> pd.DataFrame:\n",
        "    df_tweet = tweets[tweets['content'].str.len() > 15]\n",
        "    return df_tweet[['tweet_id']]\n",
        "\n",
        "# Sample test data for the tweets DataFrame\n",
        "data = {\n",
        "    'tweet_id': [1, 2, 3, 4, 5, 6, 7],\n",
        "    'content': [\n",
        "        'This tweet has more than 15 characters.',\n",
        "        'Short tweet.',\n",
        "        'Another tweet with more than 15 characters.',\n",
        "        'Short tweet.',\n",
        "        'Yet another long tweet with more than 15 characters.',\n",
        "        'One last short tweet.',\n",
        "        'Long tweet number 7 with more than 15 characters.'\n",
        "    ]\n",
        "}\n",
        "\n",
        "tweets_df = pd.DataFrame(data)\n",
        "\n",
        "# Call the invalid_tweets function with the sample test data\n",
        "result_df = invalid_tweets(tweets_df)\n",
        "\n",
        "# Print the resulting DataFrame containing the tweet_ids of tweets with content length > 15\n",
        "print(result_df)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oaZHILgpfaqk",
        "outputId": "429be61b-3127-4554-df25-b7a1d95b970a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   tweet_id\n",
            "0         1\n",
            "2         3\n",
            "4         5\n",
            "5         6\n",
            "6         7\n"
          ]
        }
      ]
    }
  ]
}